[{"categories":["Finance"],"contents":"Introduction In this article, we will explore time series data extracted from the stock market, focusing on prominent technology companies such as Apple, Amazon, Google, and Microsoft. Our objective is to equip data analysts and scientists with the essential skills to effectively manipulate and interpret stock market data.\nTo achieve this, we will utilize the yfinance library to fetch stock information and leverage visualization tools such as Seaborn and Matplotlib to illustrate various facets of the data. Specifically, we will explore methods to analyze stock risk based on historical performance, and implement predictive modeling using GRU/ LSTM models.\nThroughout this tutorial, we aim to address the following key questions:\nHow has the stock price evolved over time? What is the average daily return of the stock? How does the moving average of the stocks vary? What is the correlation between different stocks? How can we forecast future stock behavior, exemplified by predicting the closing price of Apple Inc. using LSTM or GRU?\u0026quot; Getting Data The initial step involves acquiring and loading the data into memory. Our source of stock data is the Yahoo Finance website, renowned for its wealth of financial market data and investment tools. To access this data, we\u0026rsquo;ll employ the yfinance library, known for its efficient and Pythonic approach to downloading market data from Yahoo. For further insights into yfinance, refer to the article titled Reliably download historical market data from with Python.\nInstall Dependencies pip install -qU yfinance seaborn Configuration Code import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set_style(\u0026#39;whitegrid\u0026#39;) plt.style.use(\u0026#34;fivethirtyeight\u0026#34;) %matplotlib inline #comment if you are not using a jupyter notebook # For reading stock data from yahoo from pandas_datareader.data import DataReader import yfinance as yf from pandas_datareader import data as pdr yf.pdr_override() # For time stamps from datetime import datetime # Get Microsoft data data = yf.download(\u0026#34;MSFT\u0026#34;, start, end) Statistical Analysis on the price Summary # Summary Stats data.describe() Closing Price The closing price is the last price at which the stock is traded during the regular trading day. A stockâ€™s closing price is the standard benchmark used by investors to track its performance over time.\nplt.figure(figsize=(14, 5)) plt.plot(data[\u0026#39;Adj Close\u0026#39;], label=\u0026#39;Close Price\u0026#39;) plt.xlabel(\u0026#39;Date\u0026#39;) plt.ylabel(\u0026#39;Close Price [$]\u0026#39;) plt.title(\u0026#39;Stock Price History\u0026#39;) plt.legend() plt.show() Volume of Sales Volume is the amount of an asset or security that changes hands over some period of time, often over the course of a day. For instance, the stock trading volume would refer to the number of shares of security traded between its daily open and close. Trading volume, and changes to volume over the course of time, are important inputs for technical traders.\nplt.figure(figsize=(14, 5)) plt.plot(data[\u0026#39;Volume\u0026#39;], label=\u0026#39;Volume\u0026#39;) plt.xlabel(\u0026#39;Date\u0026#39;) plt.ylabel(\u0026#39;Volume\u0026#39;) plt.title(\u0026#39;Stock Price History\u0026#39;) plt.show() Moving Average The moving average (MA) is a simple technical analysis tool that smooths out price data by creating a constantly updated average price. The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks, or any time period the trader chooses.\nma_day = [10, 20, 50] # compute moving average (can be also done in a vectorized way) for ma in ma_day: column_name = f\u0026#34;{ma} days MA\u0026#34; data[column_name] = data[\u0026#39;Adj Close\u0026#39;].rolling(ma).mean() plt.figure(figsize=(14, 5)) data[[\u0026#39;Adj Close\u0026#39;, \u0026#39;10 days MA\u0026#39;, \u0026#39;20 days MA\u0026#39;, \u0026#39;50 days MA\u0026#39;]].plot() plt.xlabel(\u0026#39;Date\u0026#39;) plt.ylabel(\u0026#39;Volume\u0026#39;) plt.title(\u0026#39;Stock Price History\u0026#39;) plt.show() Statistical Analysis on the returns Now that we\u0026rsquo;ve done some baseline analysis, let\u0026rsquo;s go ahead and dive a little deeper. We\u0026rsquo;re now going to analyze the risk of the stock. In order to do so we\u0026rsquo;ll need to take a closer look at the daily changes of the stock, and not just its absolute value. Let\u0026rsquo;s go ahead and use pandas to retrieve teh daily returns for the Microsoft stock.\n# Compute daily return in percentage data[\u0026#39;Daily Return\u0026#39;] = data[\u0026#39;Adj Close\u0026#39;].pct_change() # simple plot plt.figure(figsize=(14, 5)) data[\u0026#39;Daily Return\u0026#39;].hist(bins=50) plt.title(\u0026#39;MSFT Daily Return Distribution\u0026#39;) plt.xlabel(\u0026#39;Daily Return\u0026#39;) plt.show() # histogram plt.figure(figsize=(8, 5)) data[\u0026#39;Daily Return\u0026#39;].plot() plt.title(\u0026#39;MSFT Daily Return\u0026#39;) plt.show() Data Preparation # Create a new dataframe with only the \u0026#39;Close column X = data.filter([\u0026#39;Adj Close\u0026#39;]) # Convert the dataframe to a numpy array X = X.values # Get the number of rows to train the model on training_data_len = int(np.ceil(len(X)*.95)) # Scale data from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler(feature_range=(0,1)) scaled_data = scaler.fit_transform(X) scaled_data Split training data into small chunks to ingest into LSTM and GRU\n# Create the training data set # Create the scaled training data set train_data = scaled_data[0:int(training_data_len), :] # Split the data into x_train and y_train data sets x_train = [] y_train = [] seq_length = 60 for i in range(seq_length, len(train_data)): x_train.append(train_data[i-60:i, 0]) y_train.append(train_data[i, 0]) if i\u0026lt;= seq_length+1: print(x_train) print(y_train, end=\u0026#34;\\n\\n\u0026#34;) # Convert the x_train and y_train to numpy arrays x_train, y_train = np.array(x_train), np.array(y_train) # Reshape the data x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) GRU Gated-Recurrent Unit (GRU) is adopted in this part\nfrom tensorflow.keras.models import Sequential from tensorflow.keras.layers import GRU, Dense, Dropout lstm_model = Sequential() lstm_model.add(GRU(units=128, return_sequences=True, input_shape=(seq_length, 1))) lstm_model.add(Dropout(0.2)) lstm_model.add(GRU(units=64, return_sequences=False)) lstm_model.add(Dropout(0.2)) lstm_model.add(Dense(units=1)) lstm_model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) lstm_model.fit(x_train, y_train, epochs=10, batch_size=8) LSTM Long Short-Term Memory (LSTM) is adopted in this part\nfrom tensorflow.keras.layers import LSTM lstm_model = Sequential() lstm_model.add(LSTM(units=128, return_sequences=True, input_shape=(seq_length, 1))) lstm_model.add(Dropout(0.2)) lstm_model.add(LSTM(units=64, return_sequences=False)) lstm_model.add(Dropout(0.2)) lstm_model.add(Dense(units=1)) lstm_model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) lstm_model.fit(x_train, y_train, epochs=10, batch_size=8) Testing Metrics root mean squared error (RMSE) # Create the testing data set # Create a new array containing scaled values from index 1543 to 2002 test_data = scaled_data[training_data_len - 60: , :] # Create the data sets x_test and y_test x_test = [] y_test = dataset[training_data_len:, :] for i in range(60, len(test_data)): x_test.append(test_data[i-60:i, 0]) # Convert the data to a numpy array x_test = np.array(x_test) # Reshape the data x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 )) # Get the models predicted price values predictions_gru = gru_model.predict(x_test) predictions_gru = scaler.inverse_transform(predictions_gru) predictions_lstm = lstm_model.predict(x_test) predictions_lstm = scaler.inverse_transform(predictions_lstm) # Get the root mean squared error (RMSE) rmse_lstm = np.sqrt(np.mean(((predictions_lstm - y_test) ** 2))) rmse_gru = np.sqrt(np.mean(((predictions_gru - y_test) ** 2))) print(f\u0026#34;LSTM RMSE: {rmse_lstm:.4f}, GRU RMSE: {rmse_gru:.4f}\u0026#34;) \u0026ldquo;LSTM RMSE: 4.2341, GRU RMSE: {3.3575}\u0026rdquo;\nTest Plot GRU-based model shows a bit better results both graphically and on MSE. However, this does not tell us anything about the actual profitability of these models.\nPossible trading performance The strategy implementation is:\nBUY: if prediction \u0026gt; actual_price SELL: if prediction \u0026lt; actual_price To close a position the next candle close is waited. However, LSTM and GRU has some offset that does not allow a proper utilization of this strategy.\nHence, the returns of the predictions are adopted.\n# Assume a trading capital of $10,000 trading_capital = 10000 pred_gru_df = pd.DataFrame(predictions_gru, columns=[\u0026#39;Price\u0026#39;]) pred_test_df = pd.DataFrame(y_test, columns=[\u0026#39;Price\u0026#39;]) pred_gru_df[\u0026#39;returns\u0026#39;] = pred_gru_df.pct_change(-1) pred_test_df[\u0026#39;returns\u0026#39;] = pred_test_df.pct_change(-1) # Compute Wins wins = ((pred_gru_df.dropna().returns\u0026lt;0) \u0026amp; (pred_test_df.dropna().returns\u0026lt;0)) | ((pred_gru_df.dropna().returns\u0026gt;0) \u0026amp; (pred_test_df.dropna().returns\u0026gt;0)) print(wins.value_counts()) returns_df = pd.concat([pred_gru_df.returns, pred_test_df.returns], axis=1).dropna() total_pos_return = pred_test_df.dropna().returns[wins].abs().sum() total_neg_return = pred_test_df.dropna().returns[np.logical_not(wins)].abs().sum() # compute final capital and compare with BUY\u0026amp;HOLD strategy final_capital = trading_capital*(1+total_pos_return-total_neg_return) benchmark_return = (valid.Close.iloc[-1] - valid.Close.iloc[0])/valid.Close.iloc[0] bench_capital = trading_capital*(1+benchmark_return) print(final_capital, bench_capital) returns True 81 False 72 Name: count, dtype: int64 10535.325897548326 9617.616876598737\nConclusion As showed in the previous section, these two simple Deep Learning models exhibits interesting positive results both regarding regression and trading metrics. The latter is particularly important, indeed a return of 5% is obtained while the stock price decreased of approximately 4%. This also lead to a very high sharpe and colmar ratio.\n","date":"June 16, 2024","hero":"/posts/finance/stock_prediction/gru/images/stock-market-prediction-using-data-mining-techniques.jpg","permalink":"http://localhost:1313/posts/finance/stock_prediction/gru/","summary":"Introduction In this article, we will explore time series data extracted from the stock market, focusing on prominent technology companies such as Apple, Amazon, Google, and Microsoft. Our objective is to equip data analysts and scientists with the essential skills to effectively manipulate and interpret stock market data.\nTo achieve this, we will utilize the yfinance library to fetch stock information and leverage visualization tools such as Seaborn and Matplotlib to illustrate various facets of the data.","tags":["Finance","Deep Learning","Forecasting"],"title":"MSFT Stock Prediction using LSTM or GRU"},{"categories":["Physics"],"contents":"What is Monte Carlo? Why is it important? Examples #1 #2 ","date":"June 12, 2024","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/physics/montecarlo_simulation/","summary":"What is Monte Carlo? Why is it important? Examples #1 #2 ","tags":["Science","Statistics"],"title":"Monte Carlo Simulation"},{"categories":["Basic"],"contents":"This is bold text, and this is emphasized text.\nVisit the Hugo website!\nHalooo ..\nWie geth\u0026rsquo;s? ","date":"June 8, 2024","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/introduction/index.md/","summary":"This is bold text, and this is emphasized text.\nVisit the Hugo website!\nHalooo ..\nWie geth\u0026rsquo;s? ","tags":["Basic","Multi-lingual"],"title":"Introduction"},{"categories":["Physics"],"contents":"What is Percolation \u0026rsquo; \u0026hellip; '\nWhy is it important? How can simulate it? ","date":"June 8, 2024","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/physics/percolation/","summary":"What is Percolation \u0026rsquo; \u0026hellip; '\nWhy is it important? How can simulate it? ","tags":["Science",""],"title":"Percolation"},{"categories":["Poems"],"contents":"Poem \u0026rsquo; \u0026hellip; '\nMessage to take home ","date":"June 8, 2024","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/poems/stacy/","summary":"Poem \u0026rsquo; \u0026hellip; '\nMessage to take home ","tags":["Poems","Art"],"title":"Stacy"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/data-science/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/nanotech/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"http://localhost:1313/posts/machine-learning/","summary":"","tags":null,"title":"Machine Learning"}]